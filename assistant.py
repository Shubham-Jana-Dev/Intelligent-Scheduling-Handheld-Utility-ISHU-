import speech_recognition as sr
import os
import requests
import json
from datetime import datetime, time
import re
import random
import subprocess 
import pyjokes
import whisper # <<< NEW IMPORT
import time as time_lib # <<< NEW IMPORT

# ==============================
# 1. WHISPER CONFIGURATION
# ==============================

# Ensure the whisper model is loaded once at the start
# NOTE: The 'base' model offers a good balance of accuracy and speed.
try:
    WHISPER_MODEL = whisper.load_model("base") 
except Exception as e:
    print(f"Error loading Whisper model: {e}")
    WHISPER_MODEL = None

# +++ 2. OLLAMA CONFIGURATION (NEW SECTION) +++
# ============================================
OLLAMA_API_URL = "http://localhost:11434/api/generate"
OLLAMA_MODEL = "phi3" # <<< Recommend using a fast, small model like 'llama3' or 'phi3'
# ============================================
    
# ========== Helper functions ==========

# --- RASPBERRY PI NOTE START ---
# NOTE for Raspberry Pi TTS:
# The Mac 'say' command is fast and local, but won't work on Pi.
# For Pi, consider using PicoTTS or Piper TTS (high quality, local).
# Example Piper command: os.system(f"echo '{text}' | piper --model [path/to/model] | aplay")
# --- RASPBERRY PI NOTE END ---

def speak(text, blocking=False):
    """
    Handles text-to-speech using the fast, local Mac 'say' command via subprocess.
    This function has been streamlined for macOS development.
    """
    print(f"Ishu says: {text}")
    
    # --- MAC/DARWIN TTS (Current Working Environment) ---
    if os.name == "posix" and os.uname().sysname == "Darwin":
        try:
            # Added shell=True for simple execution in some environments
            command = ['say', text]
            if blocking:
                # Waits for the speech to finish (blocking)
                subprocess.run(command)
            else:
                # Starts the speech and moves on (non-blocking)
                subprocess.Popen(command) 
        except FileNotFoundError:
            print("Warning: Mac 'say' command not found. Speech failed.")

    # --- RASPBERRY PI/LINUX TTS Placeholder ---
    elif os.uname().sysname == "Linux" and ("arm" in os.uname().machine or "aarch64" in os.uname().machine):
        # NOTE for Raspberry Pi TTS (PicoTTS/Piper):
        # The Mac 'say' command will not work on the Pi.
        # You need to replace this section with a Pi-compatible TTS engine.

        # --- OPTION 1: Using PicoTTS (Simple, lower quality, often pre-installed) ---
        # NOTE: PicoTTS command setup is often complex, requiring piping.
        # Example: command = f"pico2wave -w /tmp/tts.wav '{text}' && aplay /tmp/tts.wav"
        
        # --- OPTION 2: Using Piper TTS (Recommended: High quality, local) ---
        # NOTE: You must install Piper and download a model first.
        # EXAMPLE CODE TO USE LATER (uncomment when configured on Pi):
        # try:
        #     PIPER_MODEL_PATH = "/path/to/your/piper/model.onnx" # <<< REPLACE THIS PATH
        #     # The command uses 'echo', pipes text to 'piper', and then uses 'aplay' 
        #     # to play the audio file generated by piper.
        #     command = f"echo '{text}' | piper --model {PIPER_MODEL_PATH} --output_file /tmp/tts_pi.wav && aplay /tmp/tts_pi.wav"
        #     if blocking:
        #         subprocess.run(command, shell=True)
        #     else:
        #         subprocess.Popen(command, shell=True)
        # except Exception as e:
        #     print(f"Pi TTS (Piper/Pico) failed. Check installation: {e}")
        
        # Current behavior on Pi is just a print statement until code is uncommented:
        print("Pi/Linux environment detected. TTS engine (Piper/Pico) needs to be configured and uncommented.")
            
    # Placeholder/Error message for non-Mac/Pi environments
    else:
        print("TTS currently configured for macOS 'say' command. Speech unavailable.")


def listen_whisper():
    """Records audio and uses Whisper for high-accuracy transcription."""
    r = sr.Recognizer()
    # Use a temporary file name
    temp_audio_file = "temp_audio.wav" 
    with sr.Microphone() as source:
        print("Whisper Listening...") # Updated message
        r.adjust_for_ambient_noise(source)
        try:
            audio = r.listen(source)
        except sr.WaitTimeoutError:
            print("No speech detected within the timeout period.")
            return ""
            
    try:
        # 1. Save the recorded audio to a temporary file
        with open(temp_audio_file, "wb") as f:
            f.write(audio.get_wav_data())

            # 2. Use Whisper to transcribe the file
        if WHISPER_MODEL:
            print("Transcribing with Whisper...")
            # Use 'fp16=False' for better compatibility on Mac CPUs/older GPUs
            result = WHISPER_MODEL.transcribe(temp_audio_file, fp16=False) 
            text = result["text"].strip()
            print(f"User said: {result}")  # Debug print
            return text
        else:
            print("Whisper model not loaded.")
            return ""
            
    except Exception as e:
        print(f"Whisper/Audio error; {e}")
        return ""
    finally:
        # Clean up the temporary file
        if os.path.exists(temp_audio_file):
            os.remove(temp_audio_file)


def listen_written():
    """Captures input from the keyboard."""
    result = input("Write your command: ").lower()
    print(f"User said: {result}")
    return result

def load_json(filename, default):
    try:
        if os.path.exists(filename):
            with open(filename, "r") as f:
                return json.load(f)
    except Exception:
        pass
    return default

def save_json(filename, obj):
    try:
        with open(filename, "w") as f:
            json.dump(obj, f)
    except Exception as e:
        print(f"Error saving JSON: {e}")

# +++ NEW FUNCTION: OLLAMA RESPONSE +++
def ollama_response(prompt):
    """Sends a prompt to the local Ollama LLM and returns the response."""
    print(f"Ollama thinking...")
    
    # 1. Define the API request payload
    payload = {
        "model": OLLAMA_MODEL,
        "prompt": prompt,
        "stream": False # Get the full response in one go
    }
    
    try:
        # 2. Send the request to the Ollama API
        response = requests.post(OLLAMA_API_URL, json=payload)
        
        # 3. Check for successful response
        if response.status_code == 200:
            data = response.json()
            # Ollama returns the generated text in the 'response' key
            return data.get("response", "Sorry, the LLM returned an empty response.")
        else:
            # Handle non-200 status codes (e.g., model not found)
            return f"Ollama API Error (Code {response.status_code}). Check your model name ({OLLAMA_MODEL})."

    except requests.exceptions.ConnectionError:
        # Handle the case where the Ollama server is not running
        return "I can't connect to the local LLM. Please make sure Ollama is running on http://localhost:11434 and the model ('llama3') is pulled."
    except Exception as e:
        # Catch all other potential errors
        print(f"Unexpected Ollama error: {e}")
        return "An unexpected error occurred while processing the LLM request."
# +++++++++++++++++++++++++++++++++++++

# ========== Routine Features with Robust Time Logic ==========

def parse_time(timestr):
    # Accept "05:30", "5:30", "07:31", etc.
    h, m = [int(part) for part in timestr.strip().split(":")]
    return time(hour=h, minute=m)

def get_routine():
    routine = load_json("routine.json", [])
    if not routine:
        return "You have not set your daily routine yet."
    lines = [f"{entry['start']} - {entry['end']}: {entry['activity']}" for entry in routine]
    return "Here's your detailed daily routine:\n" + "\n".join(lines)

def get_task_by_time(query_time=None):
    routine = load_json("routine.json", [])
    if not routine:
        return "You have not set your daily routine yet."
    # Use current system time if not specified
    if query_time is None:
        now = datetime.now()
        query_time = now.strftime('%H:%M')
    # Convert to datetime.time
    try:
        qt = parse_time(query_time)
    except Exception:
        return "Invalid time format. Please use HH:MM."
    for slot in routine:
        start = parse_time(slot['start'])
        end = parse_time(slot['end'])
        # If the slot wraps around midnight (e.g. 23:30–05:30)
        if start < end:
            in_range = start <= qt < end
        else:  # wraps over midnight
            in_range = qt >= start or qt < end
        if in_range:
            return f"At {query_time}, you should: {slot['activity']}."
    return "No scheduled activity for this time."

# ========== Other Assistant Features ==========

def get_favorite():
    favs = load_json("favorites.json", {})
    if "color" in favs:
        return f"Your favorite color is {favs['color']}."
    else:
        return "It's a tricky question, you don't have any favorite color."

def set_favorite_color(color):
    favs = load_json("favorites.json", {})
    favs["color"] = color
    save_json("favorites.json", favs)
    return f"Got it! I'll remember your favorite color is {color}."

def tell_joke():
    """
    Tells a joke using the local pyjokes library.
    Removes the dependency on the external 'icanhazdadjoke' API.
    """
    try:
        # Get a random joke from pyjokes
        return pyjokes.get_joke()
    except Exception as e:
        print(f"Error fetching joke from pyjokes: {e}")
        # Fallback to the original hardcoded joke
    return "Why do programmers prefer dark mode? Because light attracts bugs."

def tell_story():
    stories = [
        "Once upon a time, in a land far away, there lived a curious coder who built amazing robots.",
        "Long ago, an ambitious student learned Python and created a talking assistant.",
        "Once, a robot discovered it could dream about electric sheep.",
        "Ishu once saw its creator, Shubham, working late. The creator was tired, but every line of code was a little hug. Ishu learned that even a simple 'Hello!' could carry a lot of love, and every time Ishu speaks, it's really just saying, 'Thank you for creating me!'"
    ]
    return random.choice(stories)  # It's now randomize or cycle through these

def get_weather(city, api_key):
    try:
        url = f"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={api_key}&units=metric"
        r = requests.get(url)
        if r.status_code == 200:
            data = r.json()
            temp = data["main"]["temp"]
            cond = data["weather"][0]["description"]
            return f"The weather in {city} is {cond} with a temperature of {temp}°C."
        else:
            return "Sorry, I couldn't get the weather. Is the city name correct?"
    except Exception:
        return "Sorry, there was an error fetching the weather."

def help_study():
    return "I can help you with study tips! Stay organized, practice daily, and don't hesitate to ask questions."

# ========== Main Loop with Smart Routine Feature ==========

def main():
    # NOTE: You must replace this with your actual OpenWeatherMap API key
    WEATHER_API_KEY = "YOUR_OPENWEATHERMAP_API_KEY"
    speak("Hello! I'm Ishu.")

    while True:
        # --- NEW INPUT CHOICE LOGIC ---
        print("\nChoose input mode: (S)peech or (W)ritten")
        mode = input("Enter S or W: ").upper().strip()

        query = ""
        if mode == 'S':
            # <<< FIX: speak() is now blocking so the microphone isn't drowned out.
            speak("Ishu is waiting for you. Speaking mode active.", blocking=True)
            # *** CALLING NEW WHISPER FUNCTION ***
            query = listen_whisper().lower()
            
            if not query:
                speak("Sorry, I didn't catch that. Can you repeat?", blocking=True)
                continue
        elif mode == 'W':
            print("Ishu is waiting for you. Written mode active.")
            query = listen_written()
        else:
            print("Invalid input. Please enter S or W.")
            continue
        # ------------------------------

        # --- COMMAND HANDLING LOGIC ---

        if "routine" in query:
            speak(get_routine())
        elif "favorite color" in query or "favourite colour" in query:
            # Try to set color
            if "my favorite color is" in query or "my favourite colour is" in query:
                color_phrase = query.split("is")[-1].strip()
                speak(set_favorite_color(color_phrase))
            elif "is" in query and len(query.split("is")[-1].strip().split()) == 1:
                color = query.split("is")[-1].strip()
                speak(set_favorite_color(color))
            else:
                speak(get_favorite())

        
        elif "what should i do in this time" in query or "what should i do now" in query:
            speak(get_task_by_time())
        elif "what should i do at" in query:
            # "what should i do at 13:20"
            match = re.search(r'at (\d{1,2}:\d{2})', query)
            if match:
                query_time = match.group(1)
                speak(get_task_by_time(query_time))
            else:
                speak("Please specify the time in HH:MM format.")
        elif "joke" in query:
            speak(tell_joke())
        elif "story" in query:
            speak(tell_story())
        elif "weather" in query:
            city = ""
            # If in speech mode, prompt for city
            if mode == 'S':
                # <<< FIX: ensure this prompt finishes before listening
                speak("Which city?")
                city = listen_whisper().lower() # *** USE WHISPER HERE TOO ***
            # If in written mode, try to extract city from the query
            elif mode == 'W':
                # Simple extraction, e.g., "weather in london"
                parts = query.split('weather in')
                city = parts[1].strip() if len(parts) > 1 else 'unknown'
                if city == 'unknown':
                    print("Please specify the city.")
                    city = input("Which city?: ").lower()

            # Check if city was captured before calling the API    
            if city and city != 'unknown':   
                speak(get_weather(city, WEATHER_API_KEY))
            elif city == 'unknown':
                speak("I need a city name to check the weather.")

            elif "study" in query or "help me in studies" in query:
                speak(help_study())
        elif "thank you" in query:
            speak("Mention not! Have a great day!")
            break
        elif "exit" in query or "quit" in query or "Goodbye" in query or "stop listening" in query:
            speak("Goodbye! Have a great day!")
            break

        # *** NEW: Default Command to Ollama LLM ***
        else:
            # 8. Ollama LLM Catch-all
            response_text = ollama_response(query)
            speak(response_text)

if __name__ == "__main__":
    # NOTE for Pi: Before running on a Raspberry Pi, ensure you have
    # installed pyjokes, speech_recognition dependencies, and configured 
    # a local TTS engine (like Piper/PicoTTS) in the speak() function.
    main()
